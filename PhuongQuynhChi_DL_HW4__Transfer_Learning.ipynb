{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xh4Y4j1yiDXp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10, MNIST, FashionMNIST\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 5\n",
        "momentum = 0.9"
      ],
      "metadata": {
        "id": "66Z6WLNIkDnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data Augmentation"
      ],
      "metadata": {
        "id": "H_HuhJoTkHQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    #transforms.CenterCrop(28),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)), ])  # Normalize to [-1, 1]\n",
        "\n",
        "# Load data and Apply the transformations to the dataset\n",
        "train_dataset = FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "8n3Iq2FlkDj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Finetuning"
      ],
      "metadata": {
        "id": "iPGgDchTkNjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "9keHP5OYkDhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MiniVGG(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super(MiniVGG, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size= 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size= 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size= 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size= 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Linear(256*3*3, 10)\n",
        "        nn.init.normal_(self.classifier.weight, 0, 0.01)\n",
        "        nn.init.constant_(self.classifier.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Ev_jvfSzkDe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, optimizer, train_loader):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1} - Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(\"Accuracy on the test set:\", accuracy)"
      ],
      "metadata": {
        "id": "vHRjqygZkWtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CIFAR-10"
      ],
      "metadata": {
        "id": "OcsG8tnUmnL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "O_tdgfMGkDcI",
        "outputId": "e839f7e0-a2ba-4e03-9280-b9d72110a71c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fe8561fd-2e9f-49b1-9d43-caecaaaff080\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fe8561fd-2e9f-49b1-9d43-caecaaaff080\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cifar10_mini_vgg.pth to cifar10_mini_vgg.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"cifar10_mini_vgg.pth\"\n",
        "model_cifar = MiniVGG()\n",
        "\n",
        "#Load model's weight\n",
        "#model_cifar = torch.load(path)#, map_location=torch.device(device))\n",
        "model_cifar.load_state_dict(torch.load(path,map_location=torch.device(device)), strict= False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGhIKljlkDZr",
        "outputId": "ce0a79a3-52b0-4d8d-d940-bb254c5e2683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers except the last layer\n",
        "for param in model_cifar.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Set the requires_grad attribute of the parameters in the last layer to True\n",
        "for param in model_cifar.classifier.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "DaRn2NrckDXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define loss function and optimizer\n",
        "model_cifar.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_cifar = optim.SGD(model_cifar.parameters(), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "train_model(model_cifar, optimizer_cifar, train_loader)\n",
        "\n",
        "accuracy_cifar = evaluate_model(model_cifar, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnxcgY0skDU6",
        "outputId": "5deb8058-9bd6-4d14-e16b-7b90d4254c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 0.9834894227193617\n",
            "Epoch 2 - Loss: 0.49720111854676247\n",
            "Epoch 3 - Loss: 0.4188035392859724\n",
            "Epoch 4 - Loss: 0.38705016694851774\n",
            "Epoch 5 - Loss: 0.36172874768310265\n",
            "Accuracy on the test set: 86.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MNIST"
      ],
      "metadata": {
        "id": "uSr_5bSzmvN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "boswvtG-kDSa",
        "outputId": "200f0e25-3fa2-4706-85bd-3dd15ace698a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ba536095-d40f-42ed-bb26-d1ff897e03ba\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ba536095-d40f-42ed-bb26-d1ff897e03ba\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving mnist_mini_vgg.pth to mnist_mini_vgg.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"mnist_mini_vgg.pth\"\n",
        "model_mnist = MiniVGG()\n",
        "\n",
        "model_mnist.load_state_dict(torch.load(path,map_location=torch.device(device)), strict= False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN56rhzGkDP-",
        "outputId": "4ecd50e6-87b0-4851-e648-deea985eefc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers except the last layer\n",
        "for param in model_mnist.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Set the requires_grad attribute of the parameters in the last layer to True\n",
        "for param in model_mnist.classifier.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "7icmH1_ckDNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define loss function and optimizer\n",
        "model_mnist.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_mnist = optim.SGD(model_mnist.parameters(), lr=learning_rate,momentum=momentum)\n",
        "\n",
        "train_model(model_mnist, optimizer_mnist, train_loader)\n",
        "\n",
        "accuracy_mnist = evaluate_model(model_mnist, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MNd-1RNkDKh",
        "outputId": "f811f765-ff26-44c5-eefa-26f41c0848d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 0.9384697860619152\n",
            "Epoch 2 - Loss: 0.5664113389212948\n",
            "Epoch 3 - Loss: 0.515088930360671\n",
            "Epoch 4 - Loss: 0.4898987281233517\n",
            "Epoch 5 - Loss: 0.46939070289259527\n",
            "Accuracy on the test set: 82.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train MiniVGG on FashionMnist from scratch"
      ],
      "metadata": {
        "id": "qIxm93zNoTHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_fashionmnist = MiniVGG()\n",
        "model_fashionmnist.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_fashionmnist = optim.SGD(model_fashionmnist.parameters(), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "train_model(model_fashionmnist, optimizer_fashionmnist, train_loader)\n",
        "\n",
        "accuracy_fashionmnist = evaluate_model(model_fashionmnist, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB0tNw3CkDHo",
        "outputId": "f42a80e8-caee-4983-e417-6aaadbb18c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 2.2940507166421233\n",
            "Epoch 2 - Loss: 1.0220509837431186\n",
            "Epoch 3 - Loss: 0.5833006607316958\n",
            "Epoch 4 - Loss: 0.4847709890494723\n",
            "Epoch 5 - Loss: 0.4377113067106143\n",
            "Accuracy on the test set: 84.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### More Epochs"
      ],
      "metadata": {
        "id": "50PEoi1ADcaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "momentum = 0.9"
      ],
      "metadata": {
        "id": "T9kga4D6cHQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cifar.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_cifar = optim.SGD(model_cifar.parameters(), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "train_model(model_cifar, optimizer_cifar, train_loader)\n",
        "\n",
        "accuracy_cifar = evaluate_model(model_cifar, test_loader)"
      ],
      "metadata": {
        "id": "jrAHnKGScHTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40b0c2f8-4fe8-4017-e549-d0cd7726bb4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 0.299446892438095\n",
            "Epoch 2 - Loss: 0.2980200051189041\n",
            "Epoch 3 - Loss: 0.29640491365560334\n",
            "Epoch 4 - Loss: 0.29407043786032366\n",
            "Epoch 5 - Loss: 0.2943989848896766\n",
            "Epoch 6 - Loss: 0.29686618575663454\n",
            "Epoch 7 - Loss: 0.2933509435528504\n",
            "Epoch 8 - Loss: 0.2940853932884329\n",
            "Epoch 9 - Loss: 0.29178385206980745\n",
            "Epoch 10 - Loss: 0.28960249278305183\n",
            "Accuracy on the test set: 88.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_mnist.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_mnist = optim.SGD(model_mnist.parameters(), lr=learning_rate,momentum=momentum)\n",
        "\n",
        "train_model(model_mnist, optimizer_mnist, train_loader)\n",
        "\n",
        "accuracy_mnist = evaluate_model(model_mnist, test_loader)"
      ],
      "metadata": {
        "id": "Cmt90rn3cHWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd98f29-f5fd-4042-d349-fab37bd061c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 0.9400641322771369\n",
            "Epoch 2 - Loss: 0.5654646414778889\n",
            "Epoch 3 - Loss: 0.513222890637958\n",
            "Epoch 4 - Loss: 0.49015440626629886\n",
            "Epoch 5 - Loss: 0.47014945198986324\n",
            "Epoch 6 - Loss: 0.45908363031616595\n",
            "Epoch 7 - Loss: 0.4499325364160894\n",
            "Epoch 8 - Loss: 0.443547547673747\n",
            "Epoch 9 - Loss: 0.43644356455947797\n",
            "Epoch 10 - Loss: 0.42945727478784285\n",
            "Accuracy on the test set: 83.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_fashionmnist = MiniVGG()\n",
        "model_fashionmnist.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_fashionmnist = optim.SGD(model_fashionmnist.parameters(), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "train_model(model_fashionmnist, optimizer_fashionmnist, train_loader)\n",
        "\n",
        "accuracy_fashionmnist = evaluate_model(model_fashionmnist, test_loader)"
      ],
      "metadata": {
        "id": "7qMrneIicHZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2540e58f-7d57-4815-e149-030ea73723d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 2.199146497732541\n",
            "Epoch 2 - Loss: 0.9029427191723131\n",
            "Epoch 3 - Loss: 0.6168647531126099\n",
            "Epoch 4 - Loss: 0.5179052035659869\n",
            "Epoch 5 - Loss: 0.4676335608241146\n",
            "Epoch 6 - Loss: 0.4350304819309889\n",
            "Epoch 7 - Loss: 0.40968141995513363\n",
            "Epoch 8 - Loss: 0.3904583975831583\n",
            "Epoch 9 - Loss: 0.37391796700163943\n",
            "Epoch 10 - Loss: 0.360564165579866\n",
            "Accuracy on the test set: 86.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nhận xét\n",
        "- Khả năng tổng quan hóa của một mô hình pretrained trên tập dữ liệu gốc phụ thuộc vào mức độ tương tự giữa tập dữ liệu gốc và tập dữ liệu mới. Trong trường hợp này, CIFAR-10 và FashionMNIST đều là tập dữ liệu hình ảnh về các sản phẩm thời trang, vì vậy dữ liệu có mức độ tương tự về nội dung khá cao. Do đó, mô hình pretrained từ CIFAR-10 có khả năng tổng quan hóa tốt hơn trên tập dữ liệu FashionMNIST hơn mô hình pretrained từ MNIST. Accuracy của pretrained model CIFAR-10 là 86.65, tiếp đó là model FashionMNIST from scratch 84.28 và cuối cùng là MNIST pretrained model 82.8\n",
        "\n",
        "- Sau khi tăng số lượng epochs thì accuracy của 3 model không giống nhau. Với nhiều epochs hơn thì accuracy của cả 3 model đều tăng."
      ],
      "metadata": {
        "id": "qkBPzCb8GIGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Feature Extraction"
      ],
      "metadata": {
        "id": "4SW-VsGXpxER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.feature_extraction import get_graph_node_names\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "\n",
        "train_nodes, eval_nodes = get_graph_node_names(model_fashionmnist)"
      ],
      "metadata": {
        "id": "_yYcp_M9pwrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_nodes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFgQ6JJ6pwoX",
        "outputId": "efd41ef0-e6bf-4f6c-86ee-dca7f80930df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['x',\n",
              " 'features.0',\n",
              " 'features.1',\n",
              " 'features.2',\n",
              " 'features.3',\n",
              " 'features.4',\n",
              " 'features.5',\n",
              " 'features.6',\n",
              " 'features.7',\n",
              " 'features.8',\n",
              " 'features.9',\n",
              " 'features.10',\n",
              " 'features.11',\n",
              " 'features.12',\n",
              " 'features.13',\n",
              " 'features.14',\n",
              " 'flatten',\n",
              " 'classifier']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_feature_extractor(model_fashionmnist, train_return_nodes= train_nodes, eval_return_nodes= eval_nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzYEzmAvpwls",
        "outputId": "c470d9d7-955f-479c-8062-f244fafc9eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MiniVGG(\n",
              "  (features): Module(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Linear(in_features=2304, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_fashionmnist.features[0].weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCzs4DpipwjZ",
        "outputId": "7a0e05e0-5124-4c98-9f27-349e2c6040cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[[[-0.3964,  0.2778,  0.3302],\n",
              "          [-0.2101,  0.2822, -0.2866],\n",
              "          [-0.4060,  0.1549,  0.2292]]],\n",
              "\n",
              "\n",
              "        [[[-0.2469, -0.1236, -0.1002],\n",
              "          [-0.0329, -0.1331,  0.1899],\n",
              "          [ 0.2027,  0.1597, -0.0892]]],\n",
              "\n",
              "\n",
              "        [[[ 0.1681,  0.1100,  0.1068],\n",
              "          [ 0.2355, -0.2880, -0.1570],\n",
              "          [-0.0099,  0.2958,  0.0628]]],\n",
              "\n",
              "\n",
              "        [[[-0.0589,  0.2624,  0.2137],\n",
              "          [-0.0548,  0.3148, -0.2195],\n",
              "          [ 0.0631, -0.0386,  0.0806]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0320,  0.1809,  0.2814],\n",
              "          [-0.1598, -0.0119,  0.0256],\n",
              "          [-0.0069, -0.1713, -0.2688]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2926, -0.0017, -0.2618],\n",
              "          [ 0.1928, -0.0295,  0.3107],\n",
              "          [-0.1416,  0.2628,  0.0931]]],\n",
              "\n",
              "\n",
              "        [[[-0.0254,  0.0505, -0.1189],\n",
              "          [ 0.0190,  0.1902,  0.1115],\n",
              "          [-0.2718, -0.0822,  0.2864]]],\n",
              "\n",
              "\n",
              "        [[[-0.0006,  0.2006, -0.0590],\n",
              "          [-0.1642,  0.2700, -0.1411],\n",
              "          [ 0.1956,  0.3263, -0.3109]]],\n",
              "\n",
              "\n",
              "        [[[-0.3292, -0.1721, -0.3267],\n",
              "          [ 0.2317,  0.3154,  0.2399],\n",
              "          [ 0.2432, -0.0795, -0.1355]]],\n",
              "\n",
              "\n",
              "        [[[ 0.1601,  0.1276, -0.1501],\n",
              "          [-0.2930,  0.0700, -0.3115],\n",
              "          [ 0.1983, -0.2801, -0.1830]]],\n",
              "\n",
              "\n",
              "        [[[-0.3183, -0.0755,  0.1593],\n",
              "          [ 0.0279, -0.2570, -0.2198],\n",
              "          [-0.2367,  0.2114,  0.2615]]],\n",
              "\n",
              "\n",
              "        [[[-0.0889, -0.3496,  0.2518],\n",
              "          [ 0.1797, -0.3612,  0.1485],\n",
              "          [ 0.1913, -0.3103,  0.2218]]],\n",
              "\n",
              "\n",
              "        [[[-0.1605,  0.2513, -0.1800],\n",
              "          [ 0.2813,  0.1385,  0.2452],\n",
              "          [-0.2174, -0.0993,  0.1404]]],\n",
              "\n",
              "\n",
              "        [[[-0.1350, -0.1391,  0.3007],\n",
              "          [ 0.2951, -0.2613, -0.2671],\n",
              "          [ 0.0314,  0.0004,  0.1624]]],\n",
              "\n",
              "\n",
              "        [[[ 0.1259, -0.0677, -0.2183],\n",
              "          [ 0.1148, -0.2781, -0.0661],\n",
              "          [-0.1849,  0.2623,  0.2658]]],\n",
              "\n",
              "\n",
              "        [[[-0.0592,  0.0544,  0.0926],\n",
              "          [-0.2843,  0.1341, -0.1304],\n",
              "          [-0.1634, -0.3467,  0.0444]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2546,  0.1132, -0.1913],\n",
              "          [-0.2293,  0.0653,  0.1291],\n",
              "          [ 0.2239, -0.2833,  0.2105]]],\n",
              "\n",
              "\n",
              "        [[[-0.0496, -0.0152, -0.1299],\n",
              "          [-0.2783,  0.1701,  0.2778],\n",
              "          [-0.3592,  0.1214,  0.3286]]],\n",
              "\n",
              "\n",
              "        [[[-0.0962, -0.1200,  0.0132],\n",
              "          [-0.0741,  0.0490,  0.1422],\n",
              "          [ 0.2907, -0.1974,  0.1952]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2221,  0.1484,  0.3273],\n",
              "          [-0.1616, -0.2750, -0.3351],\n",
              "          [ 0.1025,  0.1341, -0.3391]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0205, -0.0204,  0.1724],\n",
              "          [ 0.3142,  0.3228,  0.0474],\n",
              "          [-0.0854,  0.0543,  0.3107]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2563,  0.0066,  0.3062],\n",
              "          [ 0.1118, -0.1630, -0.0363],\n",
              "          [-0.0265,  0.1879,  0.2909]]],\n",
              "\n",
              "\n",
              "        [[[-0.0293,  0.0133, -0.3005],\n",
              "          [ 0.2787, -0.0143,  0.0736],\n",
              "          [ 0.0513, -0.1360,  0.1071]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2239,  0.0573, -0.0030],\n",
              "          [ 0.0553,  0.2182, -0.3269],\n",
              "          [ 0.1180, -0.1453,  0.1380]]],\n",
              "\n",
              "\n",
              "        [[[-0.3512,  0.3158,  0.0875],\n",
              "          [-0.0909,  0.0132,  0.2838],\n",
              "          [ 0.0886,  0.0578,  0.0104]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2268, -0.1456,  0.1265],\n",
              "          [-0.1169,  0.1691,  0.1079],\n",
              "          [-0.2636,  0.2507, -0.2914]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0130,  0.2002, -0.2389],\n",
              "          [ 0.3175,  0.2892, -0.3022],\n",
              "          [ 0.3080,  0.1880, -0.0530]]],\n",
              "\n",
              "\n",
              "        [[[-0.0380,  0.1996, -0.1827],\n",
              "          [ 0.0763, -0.1445,  0.2382],\n",
              "          [ 0.1981, -0.0872,  0.2334]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2842, -0.1267,  0.1968],\n",
              "          [ 0.2565, -0.3117,  0.2415],\n",
              "          [-0.3303, -0.2580, -0.1076]]],\n",
              "\n",
              "\n",
              "        [[[ 0.3224, -0.2946,  0.0081],\n",
              "          [ 0.0554, -0.3098, -0.2190],\n",
              "          [ 0.1106,  0.2357,  0.0704]]],\n",
              "\n",
              "\n",
              "        [[[-0.1720,  0.2464, -0.2109],\n",
              "          [ 0.3216, -0.0653, -0.2396],\n",
              "          [ 0.2757,  0.0565,  0.1612]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2540,  0.1239,  0.3311],\n",
              "          [ 0.2638, -0.2262,  0.0492],\n",
              "          [ 0.1015, -0.2301, -0.0120]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2731,  0.2001,  0.1734],\n",
              "          [ 0.1981,  0.3199, -0.0811],\n",
              "          [ 0.2886, -0.3172,  0.2340]]],\n",
              "\n",
              "\n",
              "        [[[-0.1170,  0.2409,  0.1978],\n",
              "          [-0.3079,  0.0248, -0.1146],\n",
              "          [-0.2018,  0.0528, -0.1123]]],\n",
              "\n",
              "\n",
              "        [[[ 0.1701, -0.1506, -0.0091],\n",
              "          [-0.0919, -0.1181,  0.1328],\n",
              "          [-0.2466, -0.1466, -0.1965]]],\n",
              "\n",
              "\n",
              "        [[[-0.3358, -0.1404,  0.1343],\n",
              "          [ 0.0198, -0.1695, -0.1710],\n",
              "          [ 0.0456, -0.1770,  0.3533]]],\n",
              "\n",
              "\n",
              "        [[[-0.3614,  0.1439,  0.2518],\n",
              "          [-0.0333, -0.1112,  0.1211],\n",
              "          [-0.3596,  0.3270,  0.2675]]],\n",
              "\n",
              "\n",
              "        [[[-0.0602, -0.0023, -0.3247],\n",
              "          [-0.0901, -0.3011, -0.2531],\n",
              "          [ 0.2499,  0.3260,  0.1052]]],\n",
              "\n",
              "\n",
              "        [[[-0.0499,  0.2959, -0.2056],\n",
              "          [-0.1152,  0.3197,  0.0249],\n",
              "          [-0.1544,  0.1071,  0.3289]]],\n",
              "\n",
              "\n",
              "        [[[-0.0778,  0.2166,  0.0966],\n",
              "          [ 0.2053,  0.3066, -0.3098],\n",
              "          [-0.1652, -0.0121,  0.0530]]],\n",
              "\n",
              "\n",
              "        [[[-0.1071, -0.1810, -0.0026],\n",
              "          [ 0.2530,  0.2477, -0.2899],\n",
              "          [-0.0679, -0.2497, -0.1673]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2439,  0.0796,  0.0710],\n",
              "          [ 0.1419,  0.3396,  0.2362],\n",
              "          [-0.2861,  0.0117, -0.0085]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2377,  0.1310, -0.0759],\n",
              "          [ 0.0167,  0.1244, -0.0735],\n",
              "          [ 0.2014,  0.1808,  0.0098]]],\n",
              "\n",
              "\n",
              "        [[[-0.2427, -0.3277, -0.3298],\n",
              "          [-0.3379, -0.1660, -0.1302],\n",
              "          [-0.0246, -0.2899, -0.2562]]],\n",
              "\n",
              "\n",
              "        [[[-0.0305, -0.0850,  0.2665],\n",
              "          [ 0.1180, -0.3066, -0.2443],\n",
              "          [-0.1111,  0.1923,  0.2946]]],\n",
              "\n",
              "\n",
              "        [[[-0.3372, -0.2803,  0.1205],\n",
              "          [-0.3776,  0.2293,  0.3758],\n",
              "          [-0.3697, -0.2930,  0.1007]]],\n",
              "\n",
              "\n",
              "        [[[-0.0657, -0.1828, -0.1753],\n",
              "          [-0.3295, -0.2497,  0.1052],\n",
              "          [ 0.3231,  0.1959,  0.0206]]],\n",
              "\n",
              "\n",
              "        [[[-0.2474,  0.3319,  0.0341],\n",
              "          [ 0.1141, -0.0849,  0.1814],\n",
              "          [-0.2941,  0.1604, -0.0223]]],\n",
              "\n",
              "\n",
              "        [[[-0.3341, -0.0976,  0.0241],\n",
              "          [-0.1938,  0.3063,  0.1584],\n",
              "          [-0.0904,  0.1810,  0.2983]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2542, -0.3315, -0.0570],\n",
              "          [-0.0793, -0.2577, -0.3069],\n",
              "          [-0.2402,  0.2307,  0.2120]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0360, -0.2066,  0.1601],\n",
              "          [ 0.3301,  0.2111, -0.1314],\n",
              "          [-0.1544,  0.0474,  0.0573]]],\n",
              "\n",
              "\n",
              "        [[[-0.1088,  0.2386, -0.3165],\n",
              "          [-0.1992,  0.0927,  0.1719],\n",
              "          [-0.3454, -0.3524, -0.2074]]],\n",
              "\n",
              "\n",
              "        [[[-0.1429,  0.0745, -0.1895],\n",
              "          [-0.2978,  0.0368,  0.3405],\n",
              "          [ 0.2566, -0.1536,  0.0472]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2963,  0.0561,  0.0710],\n",
              "          [ 0.1462, -0.1228, -0.0975],\n",
              "          [-0.2028,  0.1727, -0.2875]]],\n",
              "\n",
              "\n",
              "        [[[-0.3116,  0.1824,  0.2910],\n",
              "          [ 0.1220,  0.3138, -0.0462],\n",
              "          [-0.3512, -0.2575,  0.0582]]],\n",
              "\n",
              "\n",
              "        [[[ 0.1826,  0.1945, -0.0378],\n",
              "          [ 0.2119,  0.2859, -0.2732],\n",
              "          [ 0.0236, -0.0792, -0.2378]]],\n",
              "\n",
              "\n",
              "        [[[-0.1295,  0.2240, -0.1294],\n",
              "          [-0.1038,  0.0187,  0.1639],\n",
              "          [-0.2914, -0.3605, -0.2861]]],\n",
              "\n",
              "\n",
              "        [[[ 0.3189, -0.3321, -0.3223],\n",
              "          [ 0.0414, -0.2132, -0.0028],\n",
              "          [ 0.3368, -0.1708,  0.2672]]],\n",
              "\n",
              "\n",
              "        [[[-0.3111, -0.1010,  0.0423],\n",
              "          [-0.2227,  0.0943, -0.0266],\n",
              "          [-0.2832,  0.0833,  0.0136]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2878, -0.2270,  0.2883],\n",
              "          [-0.3233, -0.1400, -0.0758],\n",
              "          [ 0.0050,  0.1034, -0.3289]]],\n",
              "\n",
              "\n",
              "        [[[-0.0502,  0.1376,  0.2015],\n",
              "          [-0.1303,  0.1538, -0.0511],\n",
              "          [-0.2444, -0.0865, -0.1146]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0890, -0.2730, -0.0220],\n",
              "          [ 0.2202, -0.2101, -0.1459],\n",
              "          [ 0.2063, -0.0180, -0.0891]]],\n",
              "\n",
              "\n",
              "        [[[-0.0051, -0.1814, -0.0696],\n",
              "          [-0.2499,  0.1867, -0.2080],\n",
              "          [ 0.1494,  0.1213, -0.3073]]],\n",
              "\n",
              "\n",
              "        [[[-0.1592,  0.0827, -0.1025],\n",
              "          [-0.0953,  0.2103,  0.1771],\n",
              "          [-0.3313,  0.0385,  0.2067]]]], device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}