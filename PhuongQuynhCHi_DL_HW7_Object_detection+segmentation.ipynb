{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgqonaGvYwzx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIBhyaXbY0tK",
        "outputId": "40417921-3f0c-44b3-91a1-4b153b002594"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import collections\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "XlF5xecFY1Pq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BOX_PATH = \"/content/drive/MyDrive/data/train_bboxes.npy\"\n",
        "IMAGE_PATH = \"/content/drive/MyDrive/data/train_X.npy\"\n",
        "LABEL_PATH = \"/content/drive/MyDrive/data/train_Y.npy\"\n",
        "SEGMENT_PATH = \"/content/drive/MyDrive/data/train_seg.npy\"\n",
        "\n",
        "train_boxes = np.load(BOX_PATH)\n",
        "train_segments = np.load(SEGMENT_PATH).reshape(55000, 64, 64)\n",
        "train_images = np.load(IMAGE_PATH)\n",
        "train_labels = np.load(LABEL_PATH)"
      ],
      "metadata": {
        "id": "JFisxhEsY_LM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#base_dir = \"/content/drive/MyDrive/mnist\"\n",
        "#os.makedirs(os.path.join(base_dir, \"image\"), exist_ok=True)\n",
        "#os.makedirs(os.path.join(base_dir, \"mask\"), exist_ok=True)\n",
        "for i in range(5000):\n",
        "  mask_file = str(i) + \"_mask.png\"\n",
        "  image_file = str(i) + \".png\"\n",
        "  img = Image.fromarray(train_images[i].reshape((64,64,3)), 'RGB')\n",
        "  img.save(os.path.join(\"/content/drive/MyDrive/mnist/segment/image/\", image_file))\n",
        "  img = Image.fromarray(train_segments[i].reshape((64,64)))\n",
        "  img.save(os.path.join(\"/content/drive/MyDrive/mnist/segment/mask/\", mask_file))"
      ],
      "metadata": {
        "id": "vdTpvlQUY_9E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BOX_PATH = \"/content/drive/MyDrive/data/valid_bboxes.npy\"\n",
        "IMAGE_PATH = \"/content/drive/MyDrive/data/valid_X.npy\"\n",
        "LABEL_PATH = \"/content/drive/MyDrive/data/valid_Y.npy\"\n",
        "SEGMENT_PATH = \"/content/drive/MyDrive/data/valid_seg.npy\"\n",
        "\n",
        "val_boxes = np.load(BOX_PATH)\n",
        "val_segments = np.load(SEGMENT_PATH).reshape(5000, 64, 64)\n",
        "val_images = np.load(IMAGE_PATH)\n",
        "val_labels = np.load(LABEL_PATH)"
      ],
      "metadata": {
        "id": "OShBLpH_cRZV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5000):\n",
        "  mask_file = str(i) + \"_mask.png\"\n",
        "  image_file = str(i) + \".png\"\n",
        "  img = Image.fromarray(val_images[i].reshape((64,64,3)), 'RGB')\n",
        "  img.save(os.path.join(\"/content/drive/MyDrive/mnist/segment/valid/image/\", image_file))\n",
        "  img = Image.fromarray(val_segments[i].reshape((64,64)))\n",
        "  img.save(os.path.join(\"/content/drive/MyDrive/mnist/segment/valid/mask/\", mask_file))"
      ],
      "metadata": {
        "id": "fuMaMqbjcIqI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "from torchvision.io import read_image\n",
        "from torchvision.ops.boxes import masks_to_boxes\n",
        "from torchvision import tv_tensors\n",
        "from torchvision.transforms.v2 import functional as F\n",
        "\n",
        "\n",
        "class MNISTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transforms):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "\n",
        "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"image\"))))\n",
        "        self.masks = list(sorted(os.listdir(os.path.join(root, \"mask\"))))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_path = os.path.join(self.root, \"image\", self.imgs[idx])\n",
        "        mask_path = os.path.join(self.root, \"mask\", self.masks[idx])\n",
        "        img = read_image(img_path)\n",
        "        mask = read_image(mask_path)\n",
        "        obj_ids = torch.unique(mask)\n",
        "        obj_ids = obj_ids[:-1]\n",
        "        num_objs = len(obj_ids)\n",
        "        masks = (mask == obj_ids[:, None, None]).to(dtype=torch.uint8)\n",
        "\n",
        "        boxes = masks_to_boxes(masks)\n",
        "\n",
        "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        image_id = idx\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        # suppose all instances are not crowd\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        # Wrap sample and targets into torchvision tv_tensors:\n",
        "        img = tv_tensors.Image(img)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = tv_tensors.BoundingBoxes(boxes, format=\"XYXY\", canvas_size=F.get_size(img))\n",
        "        target[\"masks\"] = tv_tensors.Mask(masks)\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "metadata": {
        "id": "0lxrHfycai2l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
      ],
      "metadata": {
        "id": "X0GWnedMZ2zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "530d3a59-c209-484f-b4a4-121dd1c94243"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
            "100%|██████████| 160M/160M [00:01<00:00, 126MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "\n",
        "backbone = torchvision.models.resnet50(pretrained=True)\n",
        "backbone.out_channels = 1280\n",
        "anchor_generator = AnchorGenerator(\n",
        "    sizes=((32, 64, 128, 256, 512),),\n",
        "    aspect_ratios=((0.5, 1.0, 2.0),)\n",
        ")\n",
        "\n",
        "roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
        "    featmap_names=['0'],\n",
        "    output_size=7,\n",
        "    sampling_ratio=2,\n",
        ")\n",
        "\n",
        "model = FasterRCNN(\n",
        "    backbone,\n",
        "    num_classes=10,\n",
        "    rpn_anchor_generator=anchor_generator,\n",
        "    box_roi_pool=roi_pooler,\n",
        ")\n",
        "backbone.out_channels = 1280\n"
      ],
      "metadata": {
        "id": "0zPxYL_jbHzJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c1a1ead-0984-442f-e712-4f91f966c7ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 61.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "\n",
        "\n",
        "def get_model_instance_segmentation(num_classes):\n",
        "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
        "        in_features_mask,\n",
        "        hidden_layer,\n",
        "        num_classes,\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "sLi08fRybMJz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vk0TTLQbRM-",
        "outputId": "3659b17a-1f81-4a62-9060-094584fd729b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import v2 as T\n",
        "\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    if train:\n",
        "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
        "    transforms.append(T.ToPureTensor())\n",
        "    return T.Compose(transforms)"
      ],
      "metadata": {
        "id": "4IR1-27wbWqX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "num_classes = 10\n",
        "dataset = MNISTDataset('/content/drive/MyDrive/mnist/segment', get_transform(train=True))\n",
        "dataset_test = MNISTDataset('/content/drive/MyDrive/mnist/segment/valid', get_transform(train=False))\n",
        "\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    collate_fn=utils.collate_fn\n",
        ")\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    collate_fn=utils.collate_fn\n",
        ")\n",
        "\n",
        "model = get_model_instance_segmentation(num_classes)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(\n",
        "    params,\n",
        "    lr=0.005,\n",
        "    momentum=0.9,\n",
        "    weight_decay=0.0005\n",
        ")\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer,\n",
        "    step_size=3,\n",
        "    gamma=0.1\n",
        ")\n",
        "\n",
        "# let's train it for 5 epochs\n",
        "num_epochs = 2\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=100)\n",
        "    lr_scheduler.step()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KxnILIobl02",
        "outputId": "5e5cf4f8-940b-492d-c5d1-3992bd970093"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n",
            "100%|██████████| 170M/170M [00:02<00:00, 80.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0]  [   0/2475]  eta: 5:51:42  lr: 0.000010  loss: 4.5940 (4.5940)  loss_classifier: 2.9310 (2.9310)  loss_box_reg: 0.0657 (0.0657)  loss_mask: 1.1850 (1.1850)  loss_objectness: 0.3827 (0.3827)  loss_rpn_box_reg: 0.0297 (0.0297)  time: 8.5263  data: 0.1715  max mem: 1651\n",
            "Epoch: [0]  [ 100/2475]  eta: 0:18:42  lr: 0.000509  loss: 0.9330 (1.4253)  loss_classifier: 0.1371 (0.5157)  loss_box_reg: 0.1190 (0.0979)  loss_mask: 0.6185 (0.7027)  loss_objectness: 0.0309 (0.0860)  loss_rpn_box_reg: 0.0120 (0.0230)  time: 0.3938  data: 0.0098  max mem: 1820\n",
            "Epoch: [0]  [ 200/2475]  eta: 0:16:31  lr: 0.001009  loss: 0.9402 (1.1867)  loss_classifier: 0.1473 (0.3342)  loss_box_reg: 0.1533 (0.1248)  loss_mask: 0.5936 (0.6507)  loss_objectness: 0.0217 (0.0600)  loss_rpn_box_reg: 0.0063 (0.0171)  time: 0.4087  data: 0.0087  max mem: 1820\n",
            "Epoch: [0]  [ 300/2475]  eta: 0:15:34  lr: 0.001508  loss: 1.0562 (1.1292)  loss_classifier: 0.1966 (0.2839)  loss_box_reg: 0.2148 (0.1482)  loss_mask: 0.6217 (0.6358)  loss_objectness: 0.0185 (0.0476)  loss_rpn_box_reg: 0.0041 (0.0138)  time: 0.4249  data: 0.0061  max mem: 1820\n",
            "Epoch: [0]  [ 400/2475]  eta: 0:14:52  lr: 0.002008  loss: 1.1448 (1.1141)  loss_classifier: 0.2227 (0.2618)  loss_box_reg: 0.2648 (0.1647)  loss_mask: 0.6281 (0.6304)  loss_objectness: 0.0190 (0.0445)  loss_rpn_box_reg: 0.0046 (0.0127)  time: 0.4333  data: 0.0075  max mem: 1820\n",
            "Epoch: [0]  [ 500/2475]  eta: 0:14:09  lr: 0.002507  loss: 1.0110 (1.1155)  loss_classifier: 0.1899 (0.2526)  loss_box_reg: 0.2032 (0.1809)  loss_mask: 0.5983 (0.6286)  loss_objectness: 0.0290 (0.0416)  loss_rpn_box_reg: 0.0042 (0.0118)  time: 0.4262  data: 0.0085  max mem: 1820\n",
            "Epoch: [0]  [ 600/2475]  eta: 0:13:26  lr: 0.003007  loss: 1.1265 (1.1123)  loss_classifier: 0.2352 (0.2460)  loss_box_reg: 0.2492 (0.1904)  loss_mask: 0.6201 (0.6265)  loss_objectness: 0.0170 (0.0385)  loss_rpn_box_reg: 0.0039 (0.0110)  time: 0.4325  data: 0.0076  max mem: 1820\n",
            "Epoch: [0]  [ 700/2475]  eta: 0:12:43  lr: 0.003506  loss: 1.1032 (1.1055)  loss_classifier: 0.2045 (0.2390)  loss_box_reg: 0.2368 (0.1933)  loss_mask: 0.6175 (0.6251)  loss_objectness: 0.0203 (0.0375)  loss_rpn_box_reg: 0.0039 (0.0105)  time: 0.4326  data: 0.0089  max mem: 1820\n",
            "Epoch: [0]  [ 800/2475]  eta: 0:12:00  lr: 0.004006  loss: 1.0535 (1.1066)  loss_classifier: 0.1910 (0.2355)  loss_box_reg: 0.2224 (0.1999)  loss_mask: 0.6212 (0.6245)  loss_objectness: 0.0171 (0.0364)  loss_rpn_box_reg: 0.0047 (0.0102)  time: 0.4290  data: 0.0097  max mem: 1820\n",
            "Epoch: [0]  [ 900/2475]  eta: 0:11:18  lr: 0.004505  loss: 1.0497 (1.1079)  loss_classifier: 0.1803 (0.2329)  loss_box_reg: 0.2260 (0.2058)  loss_mask: 0.6167 (0.6238)  loss_objectness: 0.0178 (0.0355)  loss_rpn_box_reg: 0.0038 (0.0098)  time: 0.4272  data: 0.0079  max mem: 1820\n",
            "Epoch: [0]  [1000/2475]  eta: 0:10:34  lr: 0.005000  loss: 1.0174 (1.1028)  loss_classifier: 0.1745 (0.2285)  loss_box_reg: 0.2098 (0.2065)  loss_mask: 0.6109 (0.6234)  loss_objectness: 0.0213 (0.0347)  loss_rpn_box_reg: 0.0051 (0.0096)  time: 0.4302  data: 0.0096  max mem: 1820\n",
            "Epoch: [0]  [1100/2475]  eta: 0:09:51  lr: 0.005000  loss: 1.0426 (1.0982)  loss_classifier: 0.1837 (0.2258)  loss_box_reg: 0.2132 (0.2074)  loss_mask: 0.6151 (0.6222)  loss_objectness: 0.0168 (0.0335)  loss_rpn_box_reg: 0.0036 (0.0093)  time: 0.4244  data: 0.0064  max mem: 1820\n",
            "Epoch: [0]  [1200/2475]  eta: 0:09:08  lr: 0.005000  loss: 1.0501 (1.0948)  loss_classifier: 0.2089 (0.2234)  loss_box_reg: 0.2423 (0.2082)  loss_mask: 0.6167 (0.6216)  loss_objectness: 0.0189 (0.0326)  loss_rpn_box_reg: 0.0038 (0.0090)  time: 0.4374  data: 0.0118  max mem: 1820\n",
            "Epoch: [0]  [1300/2475]  eta: 0:08:25  lr: 0.005000  loss: 1.0691 (1.0943)  loss_classifier: 0.1945 (0.2222)  loss_box_reg: 0.2101 (0.2097)  loss_mask: 0.6070 (0.6211)  loss_objectness: 0.0254 (0.0324)  loss_rpn_box_reg: 0.0040 (0.0089)  time: 0.4249  data: 0.0073  max mem: 1820\n",
            "Epoch: [0]  [1400/2475]  eta: 0:07:42  lr: 0.005000  loss: 1.0958 (1.0932)  loss_classifier: 0.2138 (0.2208)  loss_box_reg: 0.2449 (0.2109)  loss_mask: 0.6035 (0.6205)  loss_objectness: 0.0185 (0.0321)  loss_rpn_box_reg: 0.0048 (0.0089)  time: 0.4337  data: 0.0107  max mem: 1820\n",
            "Epoch: [0]  [1500/2475]  eta: 0:06:59  lr: 0.005000  loss: 1.0644 (1.0898)  loss_classifier: 0.1868 (0.2185)  loss_box_reg: 0.2286 (0.2109)  loss_mask: 0.6249 (0.6203)  loss_objectness: 0.0170 (0.0315)  loss_rpn_box_reg: 0.0041 (0.0087)  time: 0.4268  data: 0.0065  max mem: 1820\n",
            "Epoch: [0]  [1600/2475]  eta: 0:06:16  lr: 0.005000  loss: 1.0906 (1.0871)  loss_classifier: 0.1893 (0.2168)  loss_box_reg: 0.2203 (0.2110)  loss_mask: 0.6237 (0.6200)  loss_objectness: 0.0228 (0.0308)  loss_rpn_box_reg: 0.0050 (0.0085)  time: 0.4301  data: 0.0068  max mem: 1820\n",
            "Epoch: [0]  [1700/2475]  eta: 0:05:33  lr: 0.005000  loss: 1.0330 (1.0852)  loss_classifier: 0.1833 (0.2150)  loss_box_reg: 0.2145 (0.2106)  loss_mask: 0.6108 (0.6197)  loss_objectness: 0.0204 (0.0312)  loss_rpn_box_reg: 0.0041 (0.0086)  time: 0.4278  data: 0.0069  max mem: 1820\n",
            "Epoch: [0]  [1800/2475]  eta: 0:04:50  lr: 0.005000  loss: 1.0631 (1.0819)  loss_classifier: 0.1925 (0.2132)  loss_box_reg: 0.2211 (0.2101)  loss_mask: 0.6122 (0.6195)  loss_objectness: 0.0160 (0.0307)  loss_rpn_box_reg: 0.0038 (0.0085)  time: 0.4316  data: 0.0079  max mem: 1820\n",
            "Epoch: [0]  [1900/2475]  eta: 0:04:07  lr: 0.005000  loss: 1.0608 (1.0795)  loss_classifier: 0.1930 (0.2118)  loss_box_reg: 0.2222 (0.2099)  loss_mask: 0.6242 (0.6193)  loss_objectness: 0.0187 (0.0303)  loss_rpn_box_reg: 0.0040 (0.0084)  time: 0.4302  data: 0.0073  max mem: 1820\n",
            "Epoch: [0]  [2000/2475]  eta: 0:03:24  lr: 0.005000  loss: 1.0143 (1.0764)  loss_classifier: 0.1809 (0.2100)  loss_box_reg: 0.1959 (0.2091)  loss_mask: 0.6170 (0.6192)  loss_objectness: 0.0190 (0.0298)  loss_rpn_box_reg: 0.0061 (0.0083)  time: 0.4273  data: 0.0073  max mem: 1820\n",
            "Epoch: [0]  [2100/2475]  eta: 0:02:41  lr: 0.005000  loss: 1.0456 (1.0760)  loss_classifier: 0.1869 (0.2094)  loss_box_reg: 0.2046 (0.2095)  loss_mask: 0.6186 (0.6191)  loss_objectness: 0.0202 (0.0296)  loss_rpn_box_reg: 0.0037 (0.0082)  time: 0.4270  data: 0.0062  max mem: 1820\n",
            "Epoch: [0]  [2200/2475]  eta: 0:01:58  lr: 0.005000  loss: 1.0629 (1.0740)  loss_classifier: 0.1924 (0.2083)  loss_box_reg: 0.2239 (0.2094)  loss_mask: 0.6144 (0.6187)  loss_objectness: 0.0160 (0.0293)  loss_rpn_box_reg: 0.0045 (0.0081)  time: 0.4315  data: 0.0086  max mem: 1820\n",
            "Epoch: [0]  [2300/2475]  eta: 0:01:15  lr: 0.005000  loss: 1.0316 (1.0721)  loss_classifier: 0.1671 (0.2074)  loss_box_reg: 0.1933 (0.2091)  loss_mask: 0.6042 (0.6182)  loss_objectness: 0.0181 (0.0293)  loss_rpn_box_reg: 0.0041 (0.0081)  time: 0.4277  data: 0.0072  max mem: 1820\n",
            "Epoch: [0]  [2400/2475]  eta: 0:00:32  lr: 0.005000  loss: 1.1250 (1.0727)  loss_classifier: 0.2189 (0.2075)  loss_box_reg: 0.2597 (0.2101)  loss_mask: 0.6133 (0.6181)  loss_objectness: 0.0187 (0.0291)  loss_rpn_box_reg: 0.0059 (0.0080)  time: 0.4352  data: 0.0069  max mem: 1820\n",
            "Epoch: [0]  [2474/2475]  eta: 0:00:00  lr: 0.005000  loss: 1.0513 (1.0724)  loss_classifier: 0.1845 (0.2072)  loss_box_reg: 0.2267 (0.2104)  loss_mask: 0.6203 (0.6180)  loss_objectness: 0.0189 (0.0288)  loss_rpn_box_reg: 0.0040 (0.0080)  time: 0.4317  data: 0.0079  max mem: 1820\n",
            "Epoch: [0] Total time: 0:17:44 (0.4300 s / it)\n",
            "Epoch: [1]  [   0/2475]  eta: 0:27:38  lr: 0.005000  loss: 0.9304 (0.9304)  loss_classifier: 0.1714 (0.1714)  loss_box_reg: 0.1671 (0.1671)  loss_mask: 0.5511 (0.5511)  loss_objectness: 0.0370 (0.0370)  loss_rpn_box_reg: 0.0038 (0.0038)  time: 0.6700  data: 0.2450  max mem: 1820\n",
            "Epoch: [1]  [ 100/2475]  eta: 0:17:09  lr: 0.005000  loss: 1.1243 (1.0681)  loss_classifier: 0.2150 (0.1941)  loss_box_reg: 0.2412 (0.2135)  loss_mask: 0.6299 (0.6221)  loss_objectness: 0.0261 (0.0308)  loss_rpn_box_reg: 0.0045 (0.0076)  time: 0.4296  data: 0.0072  max mem: 1820\n",
            "Epoch: [1]  [ 200/2475]  eta: 0:16:24  lr: 0.005000  loss: 1.0630 (1.0693)  loss_classifier: 0.1882 (0.1947)  loss_box_reg: 0.2125 (0.2166)  loss_mask: 0.6224 (0.6198)  loss_objectness: 0.0208 (0.0306)  loss_rpn_box_reg: 0.0037 (0.0075)  time: 0.4300  data: 0.0076  max mem: 1820\n",
            "Epoch: [1]  [ 300/2475]  eta: 0:15:39  lr: 0.005000  loss: 1.0707 (1.0647)  loss_classifier: 0.1936 (0.1934)  loss_box_reg: 0.2211 (0.2159)  loss_mask: 0.6217 (0.6193)  loss_objectness: 0.0191 (0.0288)  loss_rpn_box_reg: 0.0034 (0.0073)  time: 0.4340  data: 0.0116  max mem: 1820\n",
            "Epoch: [1]  [ 400/2475]  eta: 0:14:56  lr: 0.005000  loss: 1.0396 (1.0602)  loss_classifier: 0.1865 (0.1928)  loss_box_reg: 0.2010 (0.2154)  loss_mask: 0.6199 (0.6182)  loss_objectness: 0.0177 (0.0269)  loss_rpn_box_reg: 0.0035 (0.0069)  time: 0.4294  data: 0.0066  max mem: 1820\n",
            "Epoch: [1]  [ 500/2475]  eta: 0:14:13  lr: 0.005000  loss: 1.0659 (1.0567)  loss_classifier: 0.1921 (0.1918)  loss_box_reg: 0.2167 (0.2146)  loss_mask: 0.6082 (0.6176)  loss_objectness: 0.0224 (0.0258)  loss_rpn_box_reg: 0.0055 (0.0069)  time: 0.4312  data: 0.0090  max mem: 1820\n",
            "Epoch: [1]  [ 600/2475]  eta: 0:13:29  lr: 0.005000  loss: 1.0790 (1.0561)  loss_classifier: 0.1969 (0.1924)  loss_box_reg: 0.2247 (0.2144)  loss_mask: 0.6149 (0.6173)  loss_objectness: 0.0159 (0.0249)  loss_rpn_box_reg: 0.0040 (0.0071)  time: 0.4280  data: 0.0064  max mem: 1820\n",
            "Epoch: [1]  [ 700/2475]  eta: 0:12:46  lr: 0.005000  loss: 1.0987 (1.0557)  loss_classifier: 0.2057 (0.1922)  loss_box_reg: 0.2470 (0.2144)  loss_mask: 0.6146 (0.6166)  loss_objectness: 0.0192 (0.0255)  loss_rpn_box_reg: 0.0026 (0.0071)  time: 0.4383  data: 0.0084  max mem: 1820\n",
            "Epoch: [1]  [ 800/2475]  eta: 0:12:02  lr: 0.005000  loss: 0.9934 (1.0515)  loss_classifier: 0.1843 (0.1911)  loss_box_reg: 0.2026 (0.2124)  loss_mask: 0.6121 (0.6163)  loss_objectness: 0.0145 (0.0248)  loss_rpn_box_reg: 0.0031 (0.0069)  time: 0.4299  data: 0.0078  max mem: 1820\n",
            "Epoch: [1]  [ 900/2475]  eta: 0:11:18  lr: 0.005000  loss: 1.0081 (1.0470)  loss_classifier: 0.1683 (0.1890)  loss_box_reg: 0.1956 (0.2101)  loss_mask: 0.6140 (0.6158)  loss_objectness: 0.0200 (0.0252)  loss_rpn_box_reg: 0.0049 (0.0070)  time: 0.4273  data: 0.0072  max mem: 1820\n",
            "Epoch: [1]  [1000/2475]  eta: 0:10:35  lr: 0.005000  loss: 1.0201 (1.0449)  loss_classifier: 0.1756 (0.1875)  loss_box_reg: 0.2029 (0.2091)  loss_mask: 0.6212 (0.6163)  loss_objectness: 0.0235 (0.0251)  loss_rpn_box_reg: 0.0044 (0.0069)  time: 0.4282  data: 0.0077  max mem: 1820\n",
            "Epoch: [1]  [1100/2475]  eta: 0:09:52  lr: 0.005000  loss: 1.0471 (1.0435)  loss_classifier: 0.1871 (0.1872)  loss_box_reg: 0.2160 (0.2081)  loss_mask: 0.6167 (0.6157)  loss_objectness: 0.0232 (0.0256)  loss_rpn_box_reg: 0.0050 (0.0069)  time: 0.4320  data: 0.0084  max mem: 1820\n",
            "Epoch: [1]  [1200/2475]  eta: 0:09:09  lr: 0.005000  loss: 0.9861 (1.0412)  loss_classifier: 0.1679 (0.1867)  loss_box_reg: 0.1836 (0.2069)  loss_mask: 0.6083 (0.6150)  loss_objectness: 0.0215 (0.0256)  loss_rpn_box_reg: 0.0035 (0.0069)  time: 0.4252  data: 0.0075  max mem: 1820\n",
            "Epoch: [1]  [1300/2475]  eta: 0:08:26  lr: 0.005000  loss: 1.0750 (1.0418)  loss_classifier: 0.1937 (0.1873)  loss_box_reg: 0.2300 (0.2075)  loss_mask: 0.6202 (0.6150)  loss_objectness: 0.0186 (0.0252)  loss_rpn_box_reg: 0.0037 (0.0068)  time: 0.4339  data: 0.0082  max mem: 1820\n",
            "Epoch: [1]  [1400/2475]  eta: 0:07:43  lr: 0.005000  loss: 1.0228 (1.0415)  loss_classifier: 0.1789 (0.1874)  loss_box_reg: 0.2037 (0.2071)  loss_mask: 0.6052 (0.6148)  loss_objectness: 0.0238 (0.0253)  loss_rpn_box_reg: 0.0051 (0.0069)  time: 0.4309  data: 0.0105  max mem: 1820\n",
            "Epoch: [1]  [1500/2475]  eta: 0:07:00  lr: 0.005000  loss: 1.0821 (1.0415)  loss_classifier: 0.2020 (0.1876)  loss_box_reg: 0.2225 (0.2070)  loss_mask: 0.6190 (0.6146)  loss_objectness: 0.0236 (0.0253)  loss_rpn_box_reg: 0.0049 (0.0070)  time: 0.4313  data: 0.0071  max mem: 1820\n",
            "Epoch: [1]  [1600/2475]  eta: 0:06:17  lr: 0.005000  loss: 1.0785 (1.0419)  loss_classifier: 0.2023 (0.1880)  loss_box_reg: 0.2318 (0.2073)  loss_mask: 0.6230 (0.6146)  loss_objectness: 0.0186 (0.0250)  loss_rpn_box_reg: 0.0039 (0.0070)  time: 0.4337  data: 0.0079  max mem: 1820\n",
            "Epoch: [1]  [1700/2475]  eta: 0:05:34  lr: 0.005000  loss: 1.0049 (1.0423)  loss_classifier: 0.1723 (0.1883)  loss_box_reg: 0.1854 (0.2074)  loss_mask: 0.6219 (0.6145)  loss_objectness: 0.0169 (0.0252)  loss_rpn_box_reg: 0.0025 (0.0070)  time: 0.4274  data: 0.0065  max mem: 1820\n",
            "Epoch: [1]  [1800/2475]  eta: 0:04:51  lr: 0.005000  loss: 1.0501 (1.0424)  loss_classifier: 0.1863 (0.1885)  loss_box_reg: 0.2102 (0.2073)  loss_mask: 0.6130 (0.6144)  loss_objectness: 0.0200 (0.0252)  loss_rpn_box_reg: 0.0039 (0.0070)  time: 0.4346  data: 0.0087  max mem: 1820\n",
            "Epoch: [1]  [1900/2475]  eta: 0:04:08  lr: 0.005000  loss: 1.1258 (1.0429)  loss_classifier: 0.2029 (0.1886)  loss_box_reg: 0.2517 (0.2074)  loss_mask: 0.6194 (0.6145)  loss_objectness: 0.0189 (0.0254)  loss_rpn_box_reg: 0.0038 (0.0071)  time: 0.4339  data: 0.0066  max mem: 1820\n",
            "Epoch: [1]  [2000/2475]  eta: 0:03:25  lr: 0.005000  loss: 1.0151 (1.0435)  loss_classifier: 0.1793 (0.1890)  loss_box_reg: 0.1903 (0.2081)  loss_mask: 0.6207 (0.6143)  loss_objectness: 0.0181 (0.0251)  loss_rpn_box_reg: 0.0034 (0.0070)  time: 0.4543  data: 0.0142  max mem: 1820\n",
            "Epoch: [1]  [2100/2475]  eta: 0:02:41  lr: 0.005000  loss: 1.0241 (1.0430)  loss_classifier: 0.1906 (0.1888)  loss_box_reg: 0.2148 (0.2080)  loss_mask: 0.6064 (0.6143)  loss_objectness: 0.0180 (0.0249)  loss_rpn_box_reg: 0.0043 (0.0069)  time: 0.4325  data: 0.0078  max mem: 1820\n",
            "Epoch: [1]  [2200/2475]  eta: 0:01:58  lr: 0.005000  loss: 1.0870 (1.0416)  loss_classifier: 0.1936 (0.1885)  loss_box_reg: 0.2253 (0.2074)  loss_mask: 0.6177 (0.6141)  loss_objectness: 0.0196 (0.0248)  loss_rpn_box_reg: 0.0036 (0.0069)  time: 0.4379  data: 0.0107  max mem: 1820\n",
            "Epoch: [1]  [2300/2475]  eta: 0:01:15  lr: 0.005000  loss: 1.0254 (1.0406)  loss_classifier: 0.1870 (0.1880)  loss_box_reg: 0.1932 (0.2068)  loss_mask: 0.6201 (0.6141)  loss_objectness: 0.0184 (0.0249)  loss_rpn_box_reg: 0.0041 (0.0069)  time: 0.4306  data: 0.0093  max mem: 1820\n",
            "Epoch: [1]  [2400/2475]  eta: 0:00:32  lr: 0.005000  loss: 0.9617 (1.0401)  loss_classifier: 0.1662 (0.1877)  loss_box_reg: 0.1728 (0.2065)  loss_mask: 0.6063 (0.6140)  loss_objectness: 0.0234 (0.0250)  loss_rpn_box_reg: 0.0048 (0.0069)  time: 0.4243  data: 0.0070  max mem: 1820\n",
            "Epoch: [1]  [2474/2475]  eta: 0:00:00  lr: 0.005000  loss: 1.0841 (1.0410)  loss_classifier: 0.2005 (0.1880)  loss_box_reg: 0.2392 (0.2069)  loss_mask: 0.6134 (0.6142)  loss_objectness: 0.0206 (0.0250)  loss_rpn_box_reg: 0.0038 (0.0069)  time: 0.4320  data: 0.0086  max mem: 1820\n",
            "Epoch: [1] Total time: 0:17:49 (0.4319 s / it)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
        "\n",
        "image = read_image(\"/content/drive/MyDrive/mnist/segment/valid/image/1.png\")\n",
        "eval_transform = get_transform(train=False)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    x = eval_transform(image)\n",
        "    x = x.to(device)\n",
        "    predictions = model([x, ])\n",
        "    pred = predictions[0]\n",
        "\n",
        "image = (255.0 * (image - image.min()) / (image.max() - image.min())).to(torch.uint8)\n",
        "image = image[:3, ...]\n",
        "pred_labels = [f\"{score:.3f}\" for label, score in zip(pred[\"labels\"], pred[\"scores\"])]\n",
        "\n",
        "\n",
        "masks = (pred[\"masks\"] > 0.9).squeeze(1)\n",
        "output_image = draw_segmentation_masks(image, masks, alpha=0.0, colors=\"blue\")\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(output_image.permute(1, 2, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DUpevI8Vd6xy",
        "outputId": "c9c9c37d-b89b-4e89-d6e2-348cd11751f6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ea24d75a230>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Object detection"
      ],
      "metadata": {
        "id": "ohQ_nQMNuxlv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BOX_PATH = \"/content/drive/MyDrive/data/valid_bboxes.npy\"\n",
        "IMAGE_PATH = \"/content/drive/MyDrive/data/valid_X.npy\"\n",
        "LABEL_PATH = \"/content/drive/MyDrive/data/valid_Y.npy\"\n",
        "SEGMENT_PATH = \"/content/drive/MyDrive/data/valid_seg.npy\"\n",
        "\n",
        "boxes = np.load(BOX_PATH)\n",
        "segments = np.load(SEGMENT_PATH)\n",
        "images = np.load(IMAGE_PATH)\n",
        "labels = np.load(LABEL_PATH)"
      ],
      "metadata": {
        "id": "1bJpAJF5muz7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(images)):\n",
        "  label_file = str(i) + \".txt\"\n",
        "  image_file = str(i) + \".png\"\n",
        "  img = Image.fromarray(images[i].reshape((64,64,3)), 'RGB')\n",
        "  img.save(os.path.join(\"/content/drive/MyDrive/detection/images/val\", image_file))\n",
        "  labels_current_image = labels[i]\n",
        "  bbox = boxes[i]\n",
        "  output_bounding_box = []\n",
        "  for line in range(len(bbox)):\n",
        "    lab = labels_current_image[line]\n",
        "    box_width = bbox[line][3] - bbox[line][1]\n",
        "    box_height = bbox[line][2] - bbox[line][0]\n",
        "    box_center_x = (bbox[line][3] + bbox[line][1]) / 2\n",
        "    box_center_y = (bbox[line][2] + bbox[line][0]) / 2\n",
        "\n",
        "    box_width_normalized = box_width / 64\n",
        "    box_height_normalized = box_height / 64\n",
        "    box_center_x_normalized = box_center_x / 64\n",
        "    box_center_y_normalized = box_center_y / 64\n",
        "    output_bounding_box.append([lab, box_center_x_normalized, box_center_y_normalized, box_width_normalized, box_height_normalized])\n",
        "  with open(os.path.join(\"/content/drive/MyDrive/detection/labels/val\", label_file),'w') as f:\n",
        "      for bounding_box in output_bounding_box:\n",
        "          f.write('{} {} {} {} {}\\n'.format(bounding_box[0],bounding_box[1],bounding_box[2],bounding_box[3],bounding_box[4]))\n"
      ],
      "metadata": {
        "id": "U5Ai6rHLmu2Y"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BOX_PATH = \"/content/drive/MyDrive/data/train_bboxes.npy\"\n",
        "IMAGE_PATH = \"/content/drive/MyDrive/data/train_X.npy\"\n",
        "LABEL_PATH = \"/content/drive/MyDrive/data/train_Y.npy\"\n",
        "SEGMENT_PATH = \"/content/drive/MyDrive/data/train_seg.npy\"\n",
        "\n",
        "boxes = np.load(BOX_PATH)\n",
        "segments = np.load(SEGMENT_PATH)\n",
        "images = np.load(IMAGE_PATH)\n",
        "labels = np.load(LABEL_PATH)"
      ],
      "metadata": {
        "id": "WqS0MrKZmu5L"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(images)):\n",
        "  label_file = str(i) + \".txt\"\n",
        "  image_file = str(i) + \".png\"\n",
        "  img = Image.fromarray(images[i].reshape((64,64,3)), 'RGB')\n",
        "  img.save(os.path.join(\"/content/drive/MyDrive/detection/images/train\", image_file))\n",
        "  labels_current_image = labels[i]\n",
        "  bbox = boxes[i]\n",
        "  output_bounding_box = []\n",
        "  for line in range(len(bbox)):\n",
        "    lab = labels_current_image[line]\n",
        "    box_width = bbox[line][3] - bbox[line][1]\n",
        "    box_height = bbox[line][2] - bbox[line][0]\n",
        "    box_center_x = (bbox[line][3] + bbox[line][1]) / 2\n",
        "    box_center_y = (bbox[line][2] + bbox[line][0]) / 2\n",
        "\n",
        "    box_width_normalized = box_width / 64\n",
        "    box_height_normalized = box_height / 64\n",
        "    box_center_x_normalized = box_center_x / 64\n",
        "    box_center_y_normalized = box_center_y / 64\n",
        "    output_bounding_box.append([lab, box_center_x_normalized, box_center_y_normalized, box_width_normalized, box_height_normalized])\n",
        "  with open(os.path.join(\"/content/drive/MyDrive/detection/labels/train\", label_file),'w') as f:\n",
        "      for bounding_box in output_bounding_box:\n",
        "          f.write('{} {} {} {} {}\\n'.format(bounding_box[0],bounding_box[1],bounding_box[2],bounding_box[3],bounding_box[4]))"
      ],
      "metadata": {
        "id": "buQpvjydmu73"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "FOLDER_PATH = '/content/drive/MyDrive/detection/labels/train'\n",
        "ROOT_PATH = '/content/drive/MyDrive/'\n",
        "print(len(os.listdir(os.path.join(ROOT_PATH, FOLDER_PATH))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfeCCvkemu-V",
        "outputId": "247235c4-9ffb-4fc5-e628-d21ef2a348a4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/detection\n",
        "!rm mydataset.yaml\n",
        "!echo 'train: /content/drive/MyDrive/detection/images/train' >> mydataset.yaml\n",
        "!echo 'val: /content/drive/MyDrive/detection/images/val' >> mydataset.yaml\n",
        "!echo 'nc: 10' >> mydataset.yaml\n",
        "!echo \"names: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\" >> mydataset.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aFzPjXcmvA5",
        "outputId": "5df59f68-3613-4c0f-8034-47ccc7da41cb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/detection\n",
            "rm: cannot remove 'mydataset.yaml': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt\n",
        "! pip install --quiet ultralytics\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb_Ttl1BmvEj",
        "outputId": "06cb2c60-03a4-400f-ed92-d369d38339e3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-17 14:27:43--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/1013abe2-be6e-4606-8433-daf2baecf594?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231117%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231117T142713Z&X-Amz-Expires=300&X-Amz-Signature=97d8235234e60e36fb8c3ec22a27b0a9882899949733133fb1c9f67cf7ace921&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8n.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-11-17 14:27:43--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/1013abe2-be6e-4606-8433-daf2baecf594?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231117%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231117T142713Z&X-Amz-Expires=300&X-Amz-Signature=97d8235234e60e36fb8c3ec22a27b0a9882899949733133fb1c9f67cf7ace921&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8n.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6534387 (6.2M) [application/octet-stream]\n",
            "Saving to: ‘yolov8n.pt’\n",
            "\n",
            "yolov8n.pt          100%[===================>]   6.23M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-11-17 14:27:43 (43.9 MB/s) - ‘yolov8n.pt’ saved [6534387/6534387]\n",
            "\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.4/645.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.train(data=\"/content/drive/MyDrive/detection/mydataset.yaml\", epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_gFjdW5nByB",
        "outputId": "66c6181c-3c9d-4fb3-efbe-cb8038109174"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.211 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/drive/MyDrive/detection/mydataset.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100%|██████████| 755k/755k [00:00<00:00, 14.8MB/s]\n",
            "Overriding model.yaml nc=80 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3012798 parameters, 3012782 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "/usr/local/lib/python3.10/dist-packages/ultralytics/utils/torch_utils.py:172: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  fusedconv.weight.copy_(torch.mm(w_bn, w_conv).view(fusedconv.weight.shape))\n",
            "/usr/local/lib/python3.10/dist-packages/ultralytics/utils/torch_utils.py:177: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  fusedconv.bias.copy_(torch.mm(w_bn, b_conv.reshape(-1, 1)).reshape(-1) + b_bn)\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/detection/labels/train... 55000 images, 0 backgrounds, 0 corrupt: 100%|██████████| 55000/55000 [02:51<00:00, 320.87it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/detection/images/train/11290.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/detection/images/train/15247.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/detection/images/train/31900.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/detection/images/train/54614.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/MyDrive/detection/images/train/54735.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/detection/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/detection/labels/val... 5000 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5000/5000 [00:17<00:00, 293.49it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/detection/labels/val.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0%|          | 0/3438 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/ultralytics/utils/loss.py:159: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  pred_dist = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n",
            "        1/5      2.73G     0.9241      1.464      1.242         24        640: 100%|██████████| 3438/3438 [21:39<00:00,  2.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/ultralytics/utils/loss.py:159: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  pred_dist = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 157/157 [00:50<00:00,  3.08it/s]\n",
            "                   all       5000      10000      0.988      0.965      0.993      0.892\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0%|          | 0/3438 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/ultralytics/utils/loss.py:159: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  pred_dist = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n",
            "        2/5      2.83G     0.6727      0.762      1.067         31        640: 100%|██████████| 3438/3438 [21:28<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/ultralytics/utils/loss.py:159: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  pred_dist = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 157/157 [00:52<00:00,  2.99it/s]\n",
            "                   all       5000      10000      0.993      0.982      0.995      0.942\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0%|          | 0/3438 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/ultralytics/utils/loss.py:159: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  pred_dist = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n",
            "        3/5      2.83G     0.5955     0.6628      1.029         34        640: 100%|██████████| 3438/3438 [21:42<00:00,  2.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/ultralytics/utils/loss.py:159: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  pred_dist = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 157/157 [00:50<00:00,  3.09it/s]\n",
            "                   all       5000      10000      0.994      0.987      0.995      0.968\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0%|          | 0/3438 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/ultralytics/utils/loss.py:159: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  pred_dist = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n",
            "        4/5      2.82G     0.5262     0.5917     0.9962         36        640: 100%|██████████| 3438/3438 [21:42<00:00,  2.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/ultralytics/utils/loss.py:159: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  pred_dist = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 157/157 [00:52<00:00,  2.98it/s]\n",
            "                   all       5000      10000      0.997       0.99      0.995       0.98\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0%|          | 0/3438 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/ultralytics/utils/loss.py:159: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  pred_dist = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n",
            "        5/5      2.83G     0.4973     0.5634      0.982         32        640: 100%|██████████| 3438/3438 [22:04<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/ultralytics/utils/loss.py:159: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  pred_dist = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 157/157 [00:52<00:00,  2.99it/s]\n",
            "                   all       5000      10000      0.995      0.992      0.995      0.984\n",
            "\n",
            "5 epochs completed in 1.885 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.211 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "/usr/local/lib/python3.10/dist-packages/ultralytics/utils/torch_utils.py:172: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  fusedconv.weight.copy_(torch.mm(w_bn, w_conv).view(fusedconv.weight.shape))\n",
            "/usr/local/lib/python3.10/dist-packages/ultralytics/utils/torch_utils.py:177: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  fusedconv.bias.copy_(torch.mm(w_bn, b_conv.reshape(-1, 1)).reshape(-1) + b_bn)\n",
            "Model summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 157/157 [00:59<00:00,  2.63it/s]\n",
            "                   all       5000      10000      0.995      0.992      0.995      0.984\n",
            "                     0       5000        976      0.995      0.994      0.995      0.986\n",
            "                     1       5000       1000      0.988      0.992      0.995      0.983\n",
            "                     2       5000       1048      0.997      0.992      0.995      0.979\n",
            "                     3       5000        980      0.994      0.997      0.995      0.984\n",
            "                     4       5000       1012      0.998      0.993      0.995      0.985\n",
            "                     5       5000        978      0.996      0.994      0.995      0.987\n",
            "                     6       5000        982      0.997      0.983      0.995      0.985\n",
            "                     7       5000        963      0.995      0.994      0.995      0.982\n",
            "                     8       5000       1035      0.996      0.988      0.995      0.984\n",
            "                     9       5000       1026      0.996      0.992      0.995      0.984\n",
            "Speed: 0.3ms preprocess, 2.2ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(\"/content/drive/MyDrive/detection/images/val/10.png\", save = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF_YvzHxnB1G",
        "outputId": "5629d0ab-e924-4bde-9759-c9e2ad08446d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ultralytics/utils/torch_utils.py:172: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  fusedconv.weight.copy_(torch.mm(w_bn, w_conv).view(fusedconv.weight.shape))\n",
            "/usr/local/lib/python3.10/dist-packages/ultralytics/utils/torch_utils.py:177: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:156.)\n",
            "  fusedconv.bias.copy_(torch.mm(w_bn, b_conv.reshape(-1, 1)).reshape(-1) + b_bn)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/detection/images/val/10.png: 640x640 1 5, 1 9, 16.5ms\n",
            "Speed: 2.5ms preprocess, 16.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(\"runs/detect/train2/10.png\")\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "Yszc0pbdnCSh",
        "outputId": "dffef1c6-2365-4ea6-c910-ca87947e9182"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ea03d8c1ab0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YTVA43vEnCWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qi4EXgJPnCYM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}